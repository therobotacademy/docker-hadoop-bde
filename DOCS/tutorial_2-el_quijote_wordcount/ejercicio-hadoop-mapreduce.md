# Hadoop con Docker: IntroducciÃ³n a MapReduce

En este ejercicio aprenderÃ¡s cÃ³mo levantar un clÃºster de Hadoop local utilizando Docker y ejecutar un proceso MapReduce sobre un archivo de texto. Este entorno reproducible permite practicar y entender los conceptos fundamentales de **procesamiento distribuido**, sin necesidad de usar recursos en la nube o clÃºsteres fÃ­sicos.

Esta ejercicio te permitirÃ¡:

- Comprender la arquitectura bÃ¡sica de Hadoop (HDFS + YARN)
- Utilizar contenedores Docker para emular un clÃºster
- Ejecutar un trabajo MapReduce real (conteo de palabras)
- Interpretar y validar resultados de salida

## Â¿QuÃ© es Hadoop?

Hadoop es un framework de software de cÃ³digo abierto para almacenar datos y ejecutar aplicaciones en clÃºsteres de hardware estÃ¡ndar. Ofrece almacenamiento distribuido (HDFS) y procesamiento paralelo (MapReduce).

**Componentes clave:**

- **HDFS (Hadoop Distributed File System):** Sistema de archivos distribuido tolerante a fallos.
- **YARN (Yet Another Resource Negotiator):** Planificador de recursos y tareas.
- **MapReduce:** Modelo de programaciÃ³n para procesamiento distribuido de datos.

## Â¿Por quÃ© usar Docker?

Instalar Hadoop puede ser complejo, especialmente para principiantes. Docker permite crear contenedores que simulan un entorno Hadoop real, ahorrando tiempo de configuraciÃ³n y garantizando que todos los estudiantes trabajen en un entorno idÃ©ntico.

## Prerequisitos

- Tener **Git** y **Docker** instalados.
- Tener conocimientos bÃ¡sicos de consola / terminal.

## Paso a paso

### 1. Clona el repositorio `BigData-Hadoop` desde GitHub

```bash
git clone https://github.com/therobotacademy/BigData-Hadoop
cd BigData-Hadoop
```

Este repositorio contiene archivos `Dockerfile` y `docker-compose.yml` que definen la infraestructura de Hadoop.

### 2. Inicia los contenedores necesarios con Docker Compose

```bash
docker-compose up -d
```

Esto levantarÃ¡ 5 contenedores:

* `namenode` (gestiona HDFS)
* `datanode` (almacena bloques de datos)
* `resourcemanager` (gestiona trabajos YARN)
* `nodemanager` (ejecuta tareas MapReduce)
* `historyserver` (para consultar trabajos pasados)

Verifica que estÃ©n corriendo:

```bash
docker ps
```
El cluster consta de los siguientes servicios (uno por contenedor):
```
                                [ ClÃºster Hadoop Docker ]
                                          â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                                               â”‚
      [ Servicios MAESTROS (Master) ]                 [ Servicios TRABAJADORES (Worker) ]
      â”‚                                               â”‚
      â”œâ”€â”€ ğŸ§  NAMENODE (Master HDFS)                   â”œâ”€â”€ ğŸ’¾ DATANODE 1 (Worker HDFS)
      â”‚    (Puerto: 9870)                             â”‚
      â”‚                                               â”œâ”€â”€ ğŸ’¾ DATANODE 2 (Worker HDFS)
      â”œâ”€â”€ ğŸ’¼ RESOURCEMANAGER (Master YARN)            â”‚
      â”‚    (Puerto: 8089)                             â”œâ”€â”€ ğŸ’¾ DATANODE 3 (Worker HDFS)
      â”‚                                               â”‚
      â””â”€â”€ ğŸ“œ HISTORYSERVER (Servicio YARN)            â””â”€â”€ ğŸ’» NODEMANAGER 1 (Worker YARN)
           (Puerto: 8188)                                  (Puerto: 8042)
```
El siguiente diagrama muestra el orden de arranque (cada flecha indica el contenedor que ha de haber arrancado previamente):

![1763053051900](image/Docker-Hadoop-explained/1763053051900.png)

### 3. Accede al contenedor `namenode`

```bash
docker exec -it namenode bash
```

AquÃ­ puedes ejecutar comandos como si fuera una terminal Linux con Hadoop configurado.

## IntroducciÃ³n al sistema de archivos HDFS

HDFS divide los archivos en bloques (por defecto 128MB) y los distribuye en varios nodos con redundancia. Para este laboratorio, crearemos la siguiente estructura de directorios:

```bash
hdfs dfs -mkdir -p /user/root/input
```

Verifica:

```bash
hdfs dfs -ls /user/root
```

### 4. Descarga un archivo de texto para analizar

Usaremos el libro *Don Quijote de La Mancha* (1 MB de texto), Ãºtil para tareas de conteo de palabras.

Puedes descargarlo desde este enlace: [el_quijote.txt](https://gist.github.com/jsdario/6d6c69398cb0c73111e49f1218960f79#file-el_quijote-txt)

### 5. Descarga el archivo `.jar` de MapReduce

Descarga el siguiente `.jar`, que contiene ejemplos precompilados de MapReduce:

ğŸ“¦ [hadoop-mapreduce-examples-2.7.1-sources.jar](https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-examples/2.7.1/)

Mueve ambos archivos al directorio del repositorio y cÃ³pialos al contenedor:

```bash
docker cp hadoop-mapreduce-examples-2.7.1-sources.jar namenode:/tmp
docker cp el_quijote.txt namenode:/tmp
```

### 6. Copia el archivo al sistema de archivos distribuido (HDFS)

Dentro del contenedor `namenode`:

```bash
cd /tmp
hdfs dfs -put el_quijote.txt /user/root/input
```

## Ejecutar un trabajo MapReduce

### Â¿QuÃ© es MapReduce?

**MapReduce** es un modelo de programaciÃ³n distribuida basado en dos funciones:

* **Map:** transforma pares clave/valor de entrada en nuevos pares intermedios.
* **Reduce:** agrupa esos pares intermedios y realiza cÃ¡lculos agregados.


Para entender cÃ³mo funciona MapReduce sin necesidad de ejecutar cÃ³digo, podemos reproducir su flujo completo utilizando una simple tabla de Excel. Este ejercicio muestra cÃ³mo se transforman los datos paso a paso a travÃ©s de las fases **Map**, **Shuffle** y **Reduce**, que son la base del procesamiento distribuido en Hadoop.

ğŸ“Š **Datos de partida**

Imaginemos que tenemos una pequeÃ±a tabla con importes de ventas por producto y tienda:

| Producto | Tienda | Importe |
| -------- | ------ | ------- |
| A        | 1      | 20      |
| B        | 1      | 30      |
| A        | 2      | 25      |
| B        | 2      | 40      |
| C        | 1      | 50      |

Nuestro objetivo serÃ¡ calcular el total vendido por cada producto, tal y como lo harÃ­a un trabajo MapReduce real.


1ï¸âƒ£ **Fase **Map**: transformar filas en pares claveâ€“valor**

En MapReduce, cada mapper procesa sus datos de entrada de forma independiente y genera pares **(clave, valor)**.
En este caso, la **clave** serÃ¡ el producto y el **valor** serÃ¡ el importe de la venta.

TransformaciÃ³n:

* (A, 20)
* (B, 30)
* (A, 25)
* (B, 40)
* (C, 50)

Cada fila produce un par.

2ï¸âƒ£ **Fase **Shuffle**: agrupar valores por clave**

Antes de llegar a los reducers, Hadoop agrupa automÃ¡ticamente todos los valores asociados a la misma clave.
Es el paso que reordena y redistribuye los datos a travÃ©s del clÃºster.

AgrupaciÃ³n obtenida:

* (A, [20, 25])
* (B, [30, 40])
* (C, [50])

AquÃ­ vemos cÃ³mo todas las ventas del mismo producto se reÃºnen para ser procesadas juntas.

3ï¸âƒ£ **Fase **Reduce**: agregaciÃ³n final**

El reducer recibe la clave y la lista de valores generada en el paso anterior. Ahora solo tiene que aplicar la operaciÃ³n correspondiente: en este caso, **sumar** los importes.

Resultados finales:

* (A, 45)
* (B, 70)
* (C, 50)

Estos serÃ­an los totales de ventas por producto.


### Ejecutar el ejemplo de WordCount

```bash
hadoop jar hadoop-mapreduce-examples-2.7.1-sources.jar org.apache.hadoop.examples.WordCount /user/root/input /user/root/output
```

Este trabajo leerÃ¡ el archivo de entrada, aplicarÃ¡ la funciÃ³n de conteo, y guardarÃ¡ la salida.

## Verificar resultados

```bash
hdfs dfs -cat /user/root/output/part-r-00000
```

Esto mostrarÃ¡ lÃ­neas como:

```
"aventura"    47  
"caballero"   91  
"molino"      12
```

Para mover el resultado a tu mÃ¡quina local:

```bash
hdfs dfs -cat /user/root/output/part-r-00000 > /tmp/quijote_wc.txt
exit
docker cp namenode:/tmp/quijote_wc.txt .
```

## Visualiza el estado del clÃºster

Puedes acceder al dashboard de Hadoop desde tu navegador:

ğŸŒ [http://localhost:9870](http://localhost:9870/)

AllÃ­ puedes consultar el sistema de archivos, nodos activos, y tareas ejecutadas.

## Apagar el clÃºster

Cuando termines:

```bash
docker-compose down
```

## Ejercicios

* ğŸ§  **Comparativa:** procesa archivos de distintos tamaÃ±os y analiza los tiempos.
* ğŸŒ **Escalado horizontal:** agrega mÃ¡s nodos `datanode` y `nodemanager` al `docker-compose.yml`.
* ğŸ“Š **VisualizaciÃ³n:** exporta el conteo y crea una nube de palabras usando Python (matplotlib + wordcloud).

---

# ğŸ“˜ Conceptos de Hadoop

**Hadoop** es un framework de cÃ³digo abierto diseÃ±ado para el almacenamiento distribuido y el procesamiento paralelo de grandes volÃºmenes de datos. Fue creado por Doug Cutting y Mike Cafarella, inspirado en los papers de Google sobre GFS (Google File System) y MapReduce.

### CaracterÃ­sticas principales:

- Escalable horizontalmente (aÃ±adiendo mÃ¡s nodos).
- Tolerante a fallos.
- Divide y conquista: divide grandes tareas en pequeÃ±as sub-tareas distribuidas.

## ğŸ”¹ HDFS (Hadoop Distributed File System)

Es el **sistema de archivos distribuido** utilizado por Hadoop. DiseÃ±ado para almacenar archivos de gran tamaÃ±o y permitir acceso eficiente desde mÃºltiples nodos.

### Â¿CÃ³mo funciona?

- **Bloques:** divide cada archivo en bloques (tÃ­picamente 128 MB).
- **ReplicaciÃ³n:** cada bloque se replica (por defecto 3 veces) en distintos DataNodes.
- **Tolerancia a fallos:** si un nodo falla, los bloques aÃºn estÃ¡n disponibles en otros.

### Componentes clave:

- **NameNode:** gestiona la estructura del sistema de archivos (metadatos).
- **DataNode:** almacena fÃ­sicamente los bloques de datos.

## ğŸ”¹ NameNode

El **NameNode** es el servidor maestro de HDFS. Mantiene la estructura del sistema de archivos (directorios, archivos, permisos, ubicaciÃ³n de bloques).

ğŸ“Œ **Nota importante:** El NameNode es crÃ­tico. Si se pierde, se pierde el acceso a todo el sistema HDFS (aunque los datos estÃ©n fÃ­sicamente en los DataNodes).

## ğŸ”¹ DataNode

El **DataNode** es el nodo esclavo que almacena los bloques de datos fÃ­sicos. Los DataNodes responden a peticiones del NameNode y permiten lectura/escritura de bloques.

- Cada DataNode puede tener mÃºltiples bloques.
- Ejecuta tareas de almacenamiento, lectura y envÃ­o de datos.

## ğŸ”¹ YARN (Yet Another Resource Negotiator)

YARN es el sistema de gestiÃ³n de recursos y ejecuciÃ³n de tareas en Hadoop. Se introdujo en Hadoop 2.0 para separar el procesamiento del almacenamiento.

### Componentes principales:

- **ResourceManager (RM):** gestiona los recursos globales del clÃºster y asigna contenedores para tareas.
- **NodeManager (NM):** gestiona los recursos y tareas en un nodo especÃ­fico.

YARN permite que mÃºltiples frameworks (como MapReduce, Spark, Tez) usen Hadoop simultÃ¡neamente.

## ğŸ”¹ MapReduce

**MapReduce** es un modelo de programaciÃ³n distribuido para el procesamiento de grandes volÃºmenes de datos en paralelo.

### Fases:

1. **Map:** toma una entrada y la transforma en pares clave-valor intermedios.
2. **Shuffle & Sort:** agrupa los pares por clave.
3. **Reduce:** aplica una funciÃ³n de agregaciÃ³n o transformaciÃ³n a cada grupo de claves.

Ejemplo tÃ­pico: **conteo de palabras**.

- `Map`: ("palabra", 1)
- `Reduce`: ("palabra", suma de ocurrencias)

MapReduce garantiza procesamiento paralelo, balanceado y escalable.

## ğŸ”¹ ResourceManager

El **ResourceManager** es el componente principal de YARN. Se encarga de:

- Asignar recursos a las tareas Map y Reduce.
- Coordinar la ejecuciÃ³n de trabajos.
- Decidir quÃ© nodos usar segÃºn disponibilidad.

## ğŸ”¹ NodeManager

Cada nodo tiene un **NodeManager** que informa al ResourceManager sobre su estado y ejecuta contenedores de tareas (Map y Reduce) en su mÃ¡quina local.

Es el agente de ejecuciÃ³n del clÃºster.

## ğŸ”¹ HistoryServer

El **HistoryServer** permite visualizar trabajos MapReduce ya finalizados. Es Ãºtil para:

- Ver logs histÃ³ricos.
- Analizar tiempos y errores.
- Realizar debugging de trabajos MapReduce.

Se accede desde la interfaz web de Hadoop.

## ğŸ”¹ Docker

**Docker** es una plataforma de virtualizaciÃ³n ligera que permite crear, ejecutar y administrar contenedores.

En este laboratorio usamos Docker para:

- Simular un clÃºster de Hadoop completo en una sola mÃ¡quina.
- Evitar instalaciones manuales complejas.
- Asegurar entornos idÃ©nticos para todos los estudiantes.

## ğŸ”¹ Docker Compose

Herramienta que permite definir y administrar mÃºltiples contenedores Docker desde un Ãºnico archivo (`docker-compose.yml`).

En nuestro caso, levanta todos los componentes de Hadoop automÃ¡ticamente.

Ejemplo:

```yaml
version: '2'
services:
  namenode:
    image: bde2020/hadoop-namenode
    ports:
      - "9870:9870"
    environment:
      - CLUSTER_NAME=test
```

## ğŸ”¹ WordCount (Ejemplo de MapReduce)

El ejemplo **WordCount** es el clÃ¡sico "Hola Mundo" de MapReduce. Cuenta cuÃ¡ntas veces aparece cada palabra en un archivo de texto.

* Mapper: divide texto en palabras â†’ ("palabra", 1)
* Reducer: suma valores de cada clave â†’ ("palabra", n)

Es Ãºtil para entender el flujo completo de MapReduce, desde la ingesta de datos hasta la agregaciÃ³n de resultados.

## ğŸ”¹ Interfaz Web de Hadoop

Hadoop incluye una interfaz web para monitorear:

* Archivos en HDFS.
* Nodos activos.
* Progreso de trabajos MapReduce.

ğŸ“ Accede desde tu navegador:
[http://localhost:9870](http://localhost:9870)

## ğŸ”¹ Comandos de HDFS mÃ¡s usados

| Comando                           | DescripciÃ³n                               |
| --------------------------------- | ------------------------------------------ |
| `hdfs dfs -mkdir`               | Crea un directorio en HDFS                 |
| `hdfs dfs -put archivo destino` | Sube archivo desde el sistema local a HDFS |
| `hdfs dfs -ls`                  | Lista archivos y directorios               |
| `hdfs dfs -cat archivo`         | Muestra el contenido de un archivo en HDFS |
| `hdfs dfs -rm`                  | Elimina un archivo de HDFS                 |

## ğŸ”¹ Comando `hadoop jar`

Permite ejecutar un `.jar` con clases Hadoop, especificando la clase principal del trabajo.

Ejemplo:

```bash
hadoop jar hadoop-mapreduce-examples-2.7.1-sources.jar org.apache.hadoop.examples.WordCount input output
```

## ğŸ”¹ Shuffle & Sort (entre Map y Reduce)

Proceso intermedio de MapReduce que:

* Agrupa todas las claves iguales.
* Reorganiza los datos para que el reducer trabaje con todos los valores de cada clave.

Este paso es transparente para el usuario pero crÃ­tico para el rendimiento.

## ğŸ”¹ ReplicaciÃ³n de datos

HDFS replica los bloques de datos automÃ¡ticamente. La configuraciÃ³n por defecto suele ser **3 rÃ©plicas** por bloque.

Esto garantiza:

* Alta disponibilidad.
* Tolerancia a fallos.
* Balanceo de carga en la lectura.

## ğŸ”¹ Escalabilidad horizontal

Hadoop estÃ¡ diseÃ±ado para escalar **aÃ±adiendo mÃ¡s nodos** (no aumentando el tamaÃ±o de un solo servidor). Esto lo diferencia de bases de datos tradicionales y es una de sus fortalezas principales.

## ğŸ”¹ Tolerancia a fallos

Si un nodo de datos falla:

* El NameNode detecta la pÃ©rdida.
* Redistribuye los bloques a otros nodos.
* No se interrumpe el procesamiento.

Hadoop fue diseÃ±ado desde cero para funcionar en entornos donde los fallos son comunes.

---

**Etiquetas:** [Docker](https://medium.com/tag/docker) Â· [Hadoop](https://medium.com/tag/hadoop) Â· [MapReduce](https://medium.com/tag/mapreduce) Â· [HDFS](https://medium.com/tag/hdfs) Â· [Big Data](https://medium.com/tag/big-data)
